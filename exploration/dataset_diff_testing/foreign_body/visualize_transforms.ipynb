{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:16:47.546583Z",
     "start_time": "2024-08-25T14:16:47.543064Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as TF\n",
    "import wandb\n",
    "from PIL import Image\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from src.models.regnety.regnety import RegNetY\n",
    "from src.utils.transform_utils import load_transforms"
   ],
   "id": "7acd0fd125160edf",
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-25T14:16:48.504027Z",
     "start_time": "2024-08-25T14:16:48.065882Z"
    }
   },
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f'mvrcii_/SEER/5wqhpp88')\n",
    "config = argparse.Namespace(**run.config)"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:16:06.491937Z",
     "start_time": "2024-08-25T14:16:06.485937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transforms_str = run.summary.get('transforms')\n",
    "_, val_transform = load_transforms(img_size=config.img_size, transforms_string=transforms_str)\n",
    "base_transform = val_transform"
   ],
   "id": "d42346a10c0362d",
   "execution_count": 18,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:13:52.079878Z",
     "start_time": "2024-08-25T14:13:52.077600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Project paths\n",
    "vissl_project_dir = 'C:\\\\Users\\Marce\\Git-Master\\JMU\\Masterarbeit\\\\vissl'\n",
    "endoscopy_project_dir = 'C:\\\\Users\\Marce\\Git-Master\\JMU\\Masterarbeit\\endoscopy'\n",
    "cvip_project_dir = 'C:\\\\Users\\Marce\\Git-Master\\Privat\\cv2024'"
   ],
   "id": "ecbc9a07203332b2",
   "execution_count": 11,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:13:55.388670Z",
     "start_time": "2024-08-25T14:13:55.380434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class_mapping_path = os.path.join(endoscopy_project_dir, 'datasets/endoextend_dataset/class_mapping.json')\n",
    "absolute_path = os.path.abspath(class_mapping_path)\n",
    "with open(class_mapping_path, 'r') as f:\n",
    "    class_mapping = json.load(f)"
   ],
   "id": "a6bb98aaf2764a42",
   "execution_count": 12,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:14:01.398953Z",
     "start_time": "2024-08-25T14:13:56.283405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ckpt_filename = 'best_epoch01_val_mAP_weighted0.67.ckpt'\n",
    "ckpt_path = os.path.join(cvip_project_dir, 'pretrained_models', ckpt_filename)\n",
    "\n",
    "model = RegNetY.load_from_checkpoint(checkpoint_path=ckpt_path, config=config, class_to_idx=class_mapping)\n",
    "model.to(torch.device('cuda'))\n",
    "model.eval();"
   ],
   "id": "6eb4d7ecb7c09910",
   "execution_count": 13,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:16:58.027858Z",
     "start_time": "2024-08-25T14:16:58.024631Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def revert_transformations(tensor):\n",
    "    \"\"\"Revert transformations applied during preprocessing, mainly normalization.\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(tensor.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(tensor.device)\n",
    "    tensor.mul_(std).add_(mean)  # Revert normalization\n",
    "    return TF.to_pil_image(tensor.cpu())  # Convert to PIL Image for visualization"
   ],
   "id": "ee9bbf74d01dbcb8",
   "execution_count": 24,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:16:58.821299Z",
     "start_time": "2024-08-25T14:16:58.817787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_and_transform_image(image_path, transform):\n",
    "    with Image.open(image_path) as img:\n",
    "        return transform(image=np.array(img.convert('RGB')))['image'].to(torch.device('cuda'))"
   ],
   "id": "4f46e4c41ed8270d",
   "execution_count": 25,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:17:03.430380Z",
     "start_time": "2024-08-25T14:17:03.426873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_image(model, val_transform, image_path):\n",
    "    img_tensor = load_and_transform_image(image_path, val_transform)\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor.unsqueeze(0)).squeeze()\n",
    "        preds = logits.argmax(dim=0).cpu().numpy()\n",
    "        probs = torch.softmax(logits, dim=0).detach().cpu().numpy()\n",
    "        return preds, img_tensor, probs"
   ],
   "id": "821e7765900d9420",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:17:04.819283Z",
     "start_time": "2024-08-25T14:17:04.815830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def list_image_files(path: str, extensions=None) -> list:\n",
    "    \"\"\"List all image files in a directory, handling multiple extensions.\"\"\"\n",
    "    if extensions is None:\n",
    "        extensions = ['.jpg', '.jpeg', '.png', '.tif', '.tiff', '.bmp', '.gif']\n",
    "    images = []\n",
    "    for extension in extensions:\n",
    "        images.extend(glob.glob(os.path.join(path, '**', '*' + extension), recursive=True))\n",
    "    return images"
   ],
   "id": "363b73326ad8e505",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:17:05.657159Z",
     "start_time": "2024-08-25T14:17:05.654156Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def idx_to_label(idx, class_mapping):\n",
    "    return {v: k for k, v in class_mapping.items()}[idx]"
   ],
   "id": "5d3e5bf971635c91",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:17:08.961536Z",
     "start_time": "2024-08-25T14:17:08.874746Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load all foreign_body images\n",
    "cvip_imgs = list_image_files('cvip')\n",
    "ee_imgs = list_image_files('endoextend')\n",
    "\n",
    "# Identify common filenames\n",
    "filenames1 = {os.path.basename(path) for path in cvip_imgs}\n",
    "filenames2 = {os.path.basename(path) for path in ee_imgs}\n",
    "common_filenames = filenames1.intersection(filenames2)\n",
    "\n",
    "# Extract common images\n",
    "cvip_images = [path for path in cvip_imgs if os.path.basename(path) in common_filenames]\n",
    "ee_images = [path for path in ee_imgs if os.path.basename(path) in common_filenames]"
   ],
   "id": "11c4bd76a903e49a",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-25T14:47:04.181469Z",
     "start_time": "2024-08-25T14:47:02.223445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_size = 224\n",
    "train_transforms = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.Rotate(limit=(-180, 180)),\n",
    "    A.GaussianBlur(blur_limit=(3, 7), sigma_limit=2.55),\n",
    "    A.RandomResizedCrop(height=img_size, width=img_size, scale=(0.5, 1.0), ratio=(1.0, 1.0), interpolation=1),\n",
    "    A.Resize(height=img_size, width=img_size, interpolation=4),\n",
    "    A.GridDistortion(num_steps=3, distort_limit=(-0.09, 0.09), interpolation=0, border_mode=0),\n",
    "    A.ColorJitter(p=0.5, brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.05, 0.05)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "def plot_image(img_orig, img_trans):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "    ax[0].imshow(img_orig)\n",
    "    ax[0].set_title(f'Original Image')\n",
    "    ax[0].axis('off')\n",
    "\n",
    "    ax[1].imshow(img_trans)\n",
    "    ax[1].set_title(f'Transformed Image')\n",
    "    ax[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "all_images = ee_images\n",
    "for i in range(0, 10):\n",
    "    image_tensor = load_and_transform_image(all_images[i], train_transforms)\n",
    "    img_trans = TF.to_pil_image(image_tensor.cpu())\n",
    "    img_orig = Image.open(all_images[i])\n",
    "    plot_image(img_orig, img_trans)"
   ],
   "id": "96d13ad4d8320df8",
   "execution_count": 90,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
