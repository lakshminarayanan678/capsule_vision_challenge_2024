{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d2bf2be1-cd9f-4aba-82fa-3c5530ed2901",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# Define the directory paths\n",
    "train_dir = '../data/training'\n",
    "val_dir = '../data/validation'\n",
    "img_size = 224\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.dataset = datasets.ImageFolder(root=root_dir)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.dataset[idx]\n",
    "        img = np.array(img)  # Convert PIL image to numpy array\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=img)\n",
    "            img = augmented['image']\n",
    "\n",
    "        return img, label\n",
    "\n",
    "\n",
    "# Define the transformations\n",
    "train_transforms = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size, interpolation=2),\n",
    "    A.Blur(p=0.1, blur_limit=(3, 7)),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Rotate(always_apply=False, p=1.0, limit=(-180, 180), interpolation=1, border_mode=0, value=(0, 0, 0), mask_value=None, rotate_method='largest_box', crop_border=False),\n",
    "    A.ColorJitter(p=0.5, brightness=(0.6, 1.4), contrast=(0.6, 1.4), saturation=(0.6, 1.4), hue=(-0.1, 0.1)),\n",
    "    #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transforms = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size, interpolation=2),\n",
    "    A.CenterCrop(height=img_size, width=img_size, always_apply=True),\n",
    "    #A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(always_apply=True)\n",
    "])\n",
    "\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = CustomDataset(root_dir=train_dir, transform=train_transforms)\n",
    "val_dataset = CustomDataset(root_dir=val_dir, transform=val_transforms)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "\n",
    "# Function to plot images\n",
    "def plot_images(images, titles, num_rows, num_cols):\n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax, title in zip(images, axes, titles):\n",
    "        ax.imshow(to_pil_image(img))\n",
    "        ax.set_title(title)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images from the train and val loaders\n",
    "def get_batch_images(loader):\n",
    "    images, labels = next(iter(loader))\n",
    "    return images\n",
    "\n",
    "# Get a batch of images\n",
    "train_images = get_batch_images(train_loader)\n",
    "val_images = get_batch_images(val_loader)\n",
    "\n",
    "# Convert tensors to numpy arrays for plotting\n",
    "train_images_np = [img for img in train_images]\n",
    "val_images_np = [img for img in val_images]\n",
    "\n",
    "# Plot 10 images from the train set\n",
    "plot_images(train_images_np[:10], [f'Train Image {i}' for i in range(10)], num_rows=2, num_cols=5)\n",
    "\n",
    "# Plot 10 images from the validation set\n",
    "plot_images(val_images_np[:10], [f'Val Image {i}' for i in range(10)], num_rows=2, num_cols=5)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71110fc2-0df4-4b30-80ff-af323459c122",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
